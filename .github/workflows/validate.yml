---
name: Lint & Test
on:
  # Allow this workflow to be called from other workflows. See
  # https://stackoverflow.com/questions/58457140/dependencies-between-workflows-on-github-actions.
  workflow_call:
  pull_request:
  push:
    branches: ["main"]

# Cancel in-progress jobs on PRs when new commits are pushed.
concurrency:
  group: validate-${{ github.workflow }}-${{ github.ref }}
  # Only cancel concurrent requests when we're running from a PR; otherwise, behavior is generally
  # more predictable if we allow existing jobs (e.g. validation triggered during release) to
  # complete.
  cancel-in-progress: ${{ github.event_name == 'pull_request' }}

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup

      - name: Check formatting
        run: make format.check

      - name: Lint
        run: make lint

  compile:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup

      - name: Check for compilation errors
        run: make compile

  test:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      models: read
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup

      - name: Check GitHub Models availability
        id: check-github-models
        continue-on-error: true
        run: |
          # Test if GitHub Models API is accessible.
          HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" \
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -H "Content-Type: application/json" \
            "https://models.github.ai/inference/chat/completions")

          if [ "$HTTP_CODE" = "429" ] || [ "$HTTP_CODE" = "503" ] || [ "$HTTP_CODE" = "500" ]; then
            echo "GitHub Models API returned $HTTP_CODE, will fall back to Ollama"
            echo "available=false" >> $GITHUB_OUTPUT
            exit 0
          else
            echo "GitHub Models API is available (HTTP $HTTP_CODE)"
            echo "available=true" >> $GITHUB_OUTPUT
          fi

      # Note this also starts the ollama server.
      - name: Install Ollama
        if: steps.check-github-models.outputs.available == 'false'
        uses: ai-action/setup-ollama@v1

      # See https://github.com/ai-action/setup-ollama/issues/40.
      - name: Cache Ollama
        if: steps.check-github-models.outputs.available == 'false'
        id: cache-artifacts
        uses: actions/cache@v4
        with:
          path: ~/.ollama
          key: ${{ runner.os }}-ollama

      - name: Pull Ollama model
        if: steps.check-github-models.outputs.available == 'false'
        run: |
          MODEL_NAME=$(grep -o 'ollama-model "[^"]*"' tests/test-functional.el | cut -d'"' -f2)
          ollama pull "$MODEL_NAME"

      - name: Run tests
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          # Disable GitHub Models in tests if the API is not available.
          MACHER_DISABLE_GITHUB_MODELS: ${{ steps.check-github-models.outputs.available == 'false' && 'true' || 'false' }}
        run: make test
